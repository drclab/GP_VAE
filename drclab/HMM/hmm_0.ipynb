{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [HMM](http://pyro.ai/examples/hmm.html#example-hidden-markov-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This example shows how to marginalize out discrete model variables in Pyro.\n",
    "\n",
    "#### This combines Stochastic Variational Inference (SVI) with a\n",
    "variable elimination algorithm, where we use enumeration to exactly\n",
    "marginalize out some variables from the ELBO computation. We might\n",
    "call the resulting algorithm collapsed SVI or collapsed SGVB (i.e\n",
    "collapsed Stochastic Gradient Variational Bayes). In the case where\n",
    "we exactly sum out all the latent variables (as is the case here),\n",
    "this algorithm reduces to a form of gradient-based Maximum\n",
    "Likelihood Estimation.\n",
    "\n",
    "To marginalize out discrete variables ``x`` in Pyro's SVI:\n",
    "\n",
    "1. Verify that the variable dependency structure in your model\n",
    "    admits tractable inference, i.e. the dependency graph among\n",
    "    enumerated variables should have narrow treewidth.\n",
    "2. Annotate each target each such sample site in the model\n",
    "    with ``infer={\"enumerate\": \"parallel\"}``\n",
    "3. Ensure your model can handle broadcasting of the sample values\n",
    "    of those variables\n",
    "4. Use the ``TraceEnum_ELBO`` loss inside Pyro's ``SVI``.\n",
    "\n",
    "Note that empirical results for the models defined here can be found in\n",
    "reference [1]. This paper also includes a description of the \"tensor\n",
    "variable elimination\" algorithm that Pyro uses under the hood to\n",
    "marginalize out discrete latent variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.contrib.examples.polyphonic_data_loader as poly\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, JitTraceEnum_ELBO, TraceEnum_ELBO, TraceTMC_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.ops.indexing import Vindex\n",
    "from pyro.optim import Adam\n",
    "from pyro.util import ignore_jit_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(relativeCreated) 9d %(message)s\", level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger()\n",
    "debug_handler = logging.StreamHandler(sys.stdout)\n",
    "debug_handler.setLevel(logging.DEBUG)\n",
    "debug_handler.addFilter(filter=lambda record: record.levelno <= logging.DEBUG)\n",
    "log.addHandler(debug_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](hmm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = poly.load_data(poly.JSB_CHORALES)\n",
    "sequences = data['train']['sequences']\n",
    "lengths = data['train']['sequence_lengths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequences $\\{y_1, \\dots, y_T\\}$ where each $y_t \\in \\{0,1\\}^{88}$ denotes the presence or absence of 88 distinct notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([229, 129, 88])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([229])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_0(sequences, lengths, hidden_dim, batch_size=None, include_prior=True):\n",
    "    assert not torch._C_.get_tracing_state()\n",
    "    num_sequences, max_length, data_dim = sequences.shape\n",
    "    with poutine.mask(mask=include_prior):\n",
    "        probs_x = pyro.sample( # 16 x 16\n",
    "            'probs_x',\n",
    "            dist.Dirichlet(0.9 * torch.eye([hidden_dim])+ 0.1).to_event(1)\n",
    "        )\n",
    "\n",
    "        probs_y = pyro.sample( # 16 x 88\n",
    "            'probs_y',\n",
    "            dist.Beta(0.1, 0.9).expand([hidden_dim, data_dim]).to_event(2)\n",
    "        )\n",
    "\n",
    "    tones_plate = pyro.plate('tones', data_dim, dim=-1)\n",
    "\n",
    "    \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
