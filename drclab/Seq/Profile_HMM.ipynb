{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Example: Constant + MuE (Profile HMM)](http://pyro.ai/examples/mue_profile.html#example-constant-mue-profile-hmm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A standard profile HMM model [1], which corresponds to a constant (delta function) distribution with a MuE observation [2]. \n",
    "#### This is a standard generative model of variable-length biological sequences (e.g. proteins) which does not require preprocessing the data by building a multiple sequence alignment (MSA). It can be compared to a more complex MuE model in this package, the FactorMuE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "[1] R. Durbin, S. R. Eddy, A. Krogh, and G. Mitchison (1998)\n",
    "\"Biological sequence analysis: probabilistic models of proteins and nucleic\n",
    "acids\"\n",
    "Cambridge university press\n",
    "\n",
    "[2] E. N. Weinstein, D. S. Marks (2021)\n",
    "\"A structured observation distribution for generative biological sequence\n",
    "prediction and forecasting\"\n",
    "https://www.biorxiv.org/content/10.1101/2020.07.31.231381v2.full.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "curl -O https://raw.githubusercontent.com/debbiemarkslab/MuE/master/models/examples/ve6_full.fasta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data](https://github.com/debbiemarkslab/MuE/blob/master/models/examples/ve6_full.fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "import pyro\n",
    "from mue.dataloaders import BiosequenceDataset\n",
    "from mue.models import ProfileHMM\n",
    "from pyro.optim import MultiStepLR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MuE](https://github.com/pyro-ppl/pyro/tree/dev/pyro/contrib/mue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './ve6_full.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "seq = \"\"\n",
    "with open(file, 'r') as fr:\n",
    "    for line in fr:\n",
    "        if line[0] == '>':\n",
    "           if seq !=\"\":\n",
    "                seq += \"*\"\n",
    "                seqs.append(seq)\n",
    "                seq=\"\"\n",
    "        else:\n",
    "            seq += line.strip('\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BiosequenceDataset(\n",
    "    file,\n",
    "    'fasta',\n",
    "    alphabet= 'amino-acid',\n",
    "    include_stop=False,\n",
    "    device='cpu'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_num = int(np.ceil(split*len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lengths = [len(dataset)-holdout_num, holdout_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(sum(data_lengths), device=device).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in torch._utils._accumulate(data_lengths):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = [\n",
    "    torch.utils.data.Subset(dataset, indices[(offset-length):offset])\n",
    "    for offset, length in zip(\n",
    "        torch._utils._accumulate(data_lengths),\n",
    "        data_lengths\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Small Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mult_dat = 10\n",
    "seqs = [\"BABBA\"] * mult_dat + [\"BAAB\"] * mult_dat + [\"BABBB\"] * mult_dat\n",
    "dataset = BiosequenceDataset(\n",
    "        seqs, \"list\", \"AB\", include_stop=True, device='cpu'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_seq_length = int(dataset.max_length * 1.1)\n",
    "latent_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "split = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProfileHMM(\n",
    "    latent_seq_length=latent_seq_length,\n",
    "    alphabet_length= dataset.alphabet_length,\n",
    "    prior_scale=1.0,\n",
    "    cuda=False,\n",
    "    indel_prior_bias= 10.0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = MultiStepLR(\n",
    "    {\n",
    "        'optimizer': Adam,\n",
    "        'optim_args': {'lr':0.001},\n",
    "        'milestones': json.loads(\"[]\"),\n",
    "        'gamma': 0.5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m losses \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_svi(dataset, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                         n_epochs, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                         batch_size, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                         scheduler, \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                         jit\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dulunche/GP_VAE/drclab/Seq/Profile_HMM.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m                     )\n",
      "File \u001b[0;32m~/GP_VAE/drclab/Seq/mue/models.py:236\u001b[0m, in \u001b[0;36mProfileHMM.fit_svi\u001b[0;34m(self, dataset, epochs, batch_size, scheduler, jit)\u001b[0m\n\u001b[1;32m    234\u001b[0m     seq_data \u001b[39m=\u001b[39m seq_data\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m    235\u001b[0m \u001b[39m#print(seq_data.shape)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m loss \u001b[39m=\u001b[39m svi\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m    237\u001b[0m     seq_data, torch\u001b[39m.\u001b[39;49mtensor(\u001b[39mlen\u001b[39;49m(dataset) \u001b[39m/\u001b[39;49m seq_data\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    238\u001b[0m )\n\u001b[1;32m    239\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m    240\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[39m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfor\u001b[39;00m model_trace, guide_trace \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/elbo.py:236\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles):\n\u001b[0;32m--> 236\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_trace(model, guide, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_trace\u001b[39m(\u001b[39mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m get_importance_trace(\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mflat\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/infer/enum.py:75\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     72\u001b[0m guide_trace \u001b[39m=\u001b[39m prune_subsample_sites(guide_trace)\n\u001b[1;32m     73\u001b[0m model_trace \u001b[39m=\u001b[39m prune_subsample_sites(model_trace)\n\u001b[0;32m---> 75\u001b[0m model_trace\u001b[39m.\u001b[39;49mcompute_log_prob()\n\u001b[1;32m     76\u001b[0m guide_trace\u001b[39m.\u001b[39mcompute_score_parts()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m is_validation_enabled():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/poutine/trace_struct.py:230\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlog_prob\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m site:\n\u001b[1;32m    229\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m         log_p \u001b[39m=\u001b[39m site[\u001b[39m\"\u001b[39;49m\u001b[39mfn\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mlog_prob(\n\u001b[1;32m    231\u001b[0m             site[\u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m*\u001b[39;49msite[\u001b[39m\"\u001b[39;49m\u001b[39margs\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msite[\u001b[39m\"\u001b[39;49m\u001b[39mkwargs\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    233\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    234\u001b[0m         _, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyro/distributions/torch_distribution.py:470\u001b[0m, in \u001b[0;36mExpandedDistribution.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[1;32m    467\u001b[0m     shape \u001b[39m=\u001b[39m broadcast_shape(\n\u001b[1;32m    468\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_shape, value\u001b[39m.\u001b[39mshape[: value\u001b[39m.\u001b[39mdim() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_dim]\n\u001b[1;32m    469\u001b[0m     )\n\u001b[0;32m--> 470\u001b[0m     log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_dist\u001b[39m.\u001b[39;49mlog_prob(value)\n\u001b[1;32m    471\u001b[0m     \u001b[39mreturn\u001b[39;00m log_prob\u001b[39m.\u001b[39mexpand(shape)\n",
      "File \u001b[0;32m~/GP_VAE/drclab/Seq/mue/missingdatahmm.py:100\u001b[0m, in \u001b[0;36mMissingDataDiscreteHMM.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39massert\u001b[39;00m value\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevent_shape[\u001b[39m1\u001b[39m]\n\u001b[1;32m     99\u001b[0m \u001b[39m# Combine observation and transition factors.\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m value_logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\n\u001b[1;32m    101\u001b[0m     value, torch\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_logits, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_logits\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m) \u001b[39m+\u001b[39m value_logits[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m1\u001b[39m:, \u001b[39mNone\u001b[39;00m, :]\n\u001b[1;32m    105\u001b[0m \u001b[39m# Eliminate time dimension.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "losses = model.fit_svi(dataset, \n",
    "                        n_epochs, \n",
    "                        batch_size, \n",
    "                        scheduler, \n",
    "                        jit= False\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
