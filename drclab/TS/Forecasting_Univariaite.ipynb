{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Forecasting I: univariate, heavy tailed](http://pyro.ai/examples/forecasting_i.html#Forecasting-I:-univariate,-heavy-tailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "from pyro.contrib.examples.bart import load_bart_od\n",
    "from pyro.contrib.forecast import ForecastingModel, Forecaster, backtest, eval_crps\n",
    "\n",
    "from pyro.infer.reparam import LocScaleReparam, StableReparam\n",
    "from pyro.ops.tensor_utils import periodic_cumsum, periodic_repeat, periodic_features\n",
    "from pyro.ops.stats import quantile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "assert pyro.__version__.startswith('1.8.3')\n",
    "pyro.set_rng_seed(20200221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_bart_od()\n",
    "print(dataset.keys())\n",
    "print(dataset[\"counts\"].shape)\n",
    "print(\" \".join(dataset[\"stations\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pyroâ€™s forecasting framework consists of: - a ForecastingModel base class, whose .model() method can be implemented for custom forecasting models, - a Forecaster class that trains and forecasts using ForecastingModels, and - a backtest() helper to evaluate models on a number of metrics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a simple univariate dataset, say weekly BART train ridership aggregated over all stations in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, O, D = dataset['counts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T // (24 * 7) * 24 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['counts'][:T // (24 * 7) * 24 * 7].reshape(T // (24*7), -1).sum(-1).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,3))\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(ForecastingModel):\n",
    "    # We then implement the .model() method. Since this is a generative model, it shouldn't\n",
    "    # look at data; however it is convenient to see the shape of data we're supposed to\n",
    "    # generate, so this inputs a zeros_like(data) tensor instead of the actual data.\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "\n",
    "        bias = pyro.sample('bias', dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample('weight',  dist.Normal(0,0.1).expand([feature_dim]).to_event(1))\n",
    "        predicttion = bias + (weight * covariates).sum(-1, keepdim = True)\n",
    "        # The prediction should have the same shape as zero_data (duration, obs_dim),\n",
    "        # but may have additional sample dimensions on the left.\n",
    "        assert predicttion.shape[-2:] == zero_data.shape\n",
    "\n",
    "        noise_scale = pyro.sample('noise_scale',  dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(0, noise_scale)\n",
    "\n",
    "        self.predict(noise_dist, predicttion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 0\n",
    "T2 = data.size(-2)\n",
    "T1 = T2 - 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.arange(float(T2)) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = torch.stack([time], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:T1].size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(111)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "forecaster = Forecaster(Model_1(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Drawing posterior samples from the forecaster, passing in full covariates but only partial data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [Continuous Ranked Probability Score](https://www.stat.washington.edu/raftery/Research/PDF/Gneiting2007jasa.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps = eval_crps(samples, data[T1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape, p10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.ylabel('$\\log y$ rides')\n",
    "plt.xlabel('Weeks after 2011-01-01')\n",
    "plt.title('Total weekly ridership (CRPS={:0.3g})'.format(crps))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.ylabel('$\\log y$ rides')\n",
    "plt.xlabel('Weeks after 2011-01-01')\n",
    "plt.title('Total weekly ridership (CRPS={:0.3g})'.format(crps))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Periodic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_features(T2, 365.25/7).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = torch.cat([time.unsqueeze(-1), periodic_features(T2, 365 / 7)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(111)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "forecaster = Forecaster(Model_1(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[T1:])\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Time-local random variables](http://pyro.ai/examples/forecasting_i.html#Time-local-random-variables:-self.time_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  7.1916,  -0.4106,   0.8071,   4.2164,  -6.6785, -10.1081, -10.6733,\n",
       "         -3.7762, -11.8220,   9.2675])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample('bias', dist.Normal(0, 10).expand([10]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5031e-07])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.sample('drift_scale', \n",
    "                                        dist.LogNormal(-20, 5).expand([1]).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample('bias', dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample('weight', dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "        # time-global scale parameter\n",
    "        drift_scale = pyro.sample('drift_scale', \n",
    "                                        dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        \n",
    "        # time-local iid noise inside time plate\n",
    "        with self._time_plate:\n",
    "        # We'll use a reparameterizer to improve variational fit. The model would still be\n",
    "        # correct if you removed this context manager, but the fit appears to be worse. \n",
    "            with poutine.reparam(config={'drift': LocScaleReparam()}):\n",
    "                drift = pyro.sample('drift', dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "\n",
    "        # After we sample the iid \"drift\" noise we can combine it in any time-dependent way.\n",
    "        # It is important to keep everything inside the plate independent and apply dependent\n",
    "        # transforms outside the plate.   \n",
    "\n",
    "        motion = drift.cumsum(-2) # A Brownian motion\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
